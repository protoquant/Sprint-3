
"""ftx_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ciixWL981mRNgGm2ZztRTeLnvu7aPoRF

This Project was based on collected data from FTX website using their API

I Collected DATA from 

BTC
ETH
BNB
BCH
LTC
SOL
DOT
AVAX

Importing Required Packages
"""

from datetime import datetime
from dotenv import load_dotenv
import os
import json
import pandas as pd
import requests
import time

from client import FtxClient

load_dotenv()

"""Connect to the API"""

endpoint_url = 'https://ftx.com/api/markets'

# Get all market data as JSON
all_markets = requests.get(endpoint_url).json()

# Convert JSON to Pandas DataFrame
df = pd.DataFrame(all_markets['result'])
df.set_index('name', inplace = True)

df

"""Get the Data for BitCoin"""

base_currency = 'BTC'
quote_currency = 'USD'

# Specify the base and quote currencies to get single market data
request_url = f'{endpoint_url}/{base_currency}/{quote_currency}'

# convert it to a DataFrame
df = pd.DataFrame(requests.get(request_url).json())
df['result']

# 1 day = 60 * 60 * 24 seconds
daily=str(60*60*24)

# Start date = 2022-04-01
start = datetime(2020, 5, 24).timestamp()

# Get the historical market data as JSON
historical = requests.get(
    f'{request_url}/candles?resolution={daily}&start_time={start}'
).json()

# Convert JSON to Pandas DataFrame
df = pd.DataFrame(historical['result'])

# Convert time to date
df['date'] = pd.to_datetime(
    df['time']/1000, unit='s', origin='unix'
) 

# Remove unnecessary columns
df.drop(['startTime', 'time'], axis=1, inplace=True)
df
df

## Collecting hourly and weekly data
all_BTC_data_1H = df.set_index('date').resample('1H').pad()
all_BTC_data_2H = df.set_index('date').resample('2H').pad()
all_BTC_data_4H = df.set_index('date').resample('4H').pad()
all_BTC_data_8H = df.set_index('date').resample('8H').pad()
all_BTC_data_24H = df.set_index('date').resample('24H').pad()
all_BTC_data_48H = df.set_index('date').resample('48H').pad()
all_BTC_data_72H = df.set_index('date').resample('72H').pad()

all_BTC_data_1W = df.set_index('date').resample('1W').pad()
all_BTC_data_2W = df.set_index('date').resample('2W').pad()
all_BTC_data_4W = df.set_index('date').resample('4W').pad()
all_BTC_data_8W = df.set_index('date').resample('8W').pad()
all_BTC_data_16W = df.set_index('date').resample('16W').pad()

# Save to csv format
all_BTC_data_16W.to_csv('all_btc_16W_ftx.csv')

all_BTC_data_1H.shape

"""## ETH

Get the Data For ETH
"""

base_currency = 'ETH'
quote_currency = 'USD'

# Specify the base and quote currencies to get single market data
request_url = f'{endpoint_url}/{base_currency}/{quote_currency}'

df1 = pd.DataFrame(requests.get(request_url).json())
df1['result']

# 1 day = 60 * 60 * 24 seconds
daily=str(60*60*24)

# Start date = 2022-04-01
start = datetime(2020, 1, 1).timestamp()

# Get the historical market data as JSON
historical = requests.get(
    f'{request_url}/candles?resolution={daily}&start_time={start}'
).json()

# Convert JSON to Pandas DataFrame
df1 = pd.DataFrame(historical['result'])

# Convert time to date
df1['date'] = pd.to_datetime(
    df1['time']/1000, unit='s', origin='unix'
) 

# Remove unnecessary columns
df1.drop(['startTime', 'time'], axis=1, inplace=True)
df1
df1

## Collecting hourly and weekly data
all_ETH_data_1H = df1.set_index('date').resample('1H').pad()
all_ETH_data_2H = df1.set_index('date').resample('2H').pad()
all_ETH_data_4H = df1.set_index('date').resample('4H').pad()
all_ETH_data_8H = df1.set_index('date').resample('8H').pad()
all_ETH_data_24H = df1.set_index('date').resample('24H').pad()
all_ETH_data_48H = df1.set_index('date').resample('48H').pad()
all_ETH_data_72H = df1.set_index('date').resample('72H').pad()

all_ETH_data_1W = df1.set_index('date').resample('1W').pad()
all_ETH_data_2W = df1.set_index('date').resample('2W').pad()
all_ETH_data_4W = df1.set_index('date').resample('4W').pad()
all_ETH_data_8W = df1.set_index('date').resample('8W').pad()
all_ETH_data_16W = df1.set_index('date').resample('16W').pad()

# Save to csv format
all_ETH_data_16W.to_csv('all_eth_16W_ftx.csv')

df1.to_csv('eth_ftx.csv')

"""## Get the Data for BNB"""

base_currency = 'BNB'
quote_currency = 'USD'

# Specify the base and quote currencies to get single market data
request_url = f'{endpoint_url}/{base_currency}/{quote_currency}'

df2 = pd.DataFrame(requests.get(request_url).json())
df2['result']

# 1 day = 60 * 60 * 24 seconds
daily=str(60*60*24)

# Start date = 2022-04-01
start = datetime(2020, 5, 24).timestamp()

# Get the historical market data as JSON
historical = requests.get(
    f'{request_url}/candles?resolution={daily}&start_time={start}'
).json()

# Convert JSON to Pandas DataFrame
df2 = pd.DataFrame(historical['result'])

# Convert time to date
df2['date'] = pd.to_datetime(
    df2['time']/1000, unit='s', origin='unix'
) 

# Remove unnecessary columns
df2.drop(['startTime', 'time'], axis=1, inplace=True)
df2

"""Resampling the data to collect for different time range"""
## Collecting hourly and weekly data
all_BNB_data_1H = df2.set_index('date').resample('1H').pad()
all_BNB_data_2H = df2.set_index('date').resample('2H').pad()
all_BNB_data_4H = df2.set_index('date').resample('4H').pad()
all_BNB_data_8H = df2.set_index('date').resample('8H').pad()
all_BNB_data_24H = df2.set_index('date').resample('24H').pad()
all_BNB_data_48H = df2.set_index('date').resample('48H').pad()
all_BNB_data_72H = df2.set_index('date').resample('72H').pad()

all_BNB_data_1W = df2.set_index('date').resample('1W').pad()
all_BNB_data_2W = df2.set_index('date').resample('2W').pad()
all_BNB_data_4W = df2.set_index('date').resample('4W').pad()
all_BNB_data_8W = df2.set_index('date').resample('8W').pad()
all_BNB_data_16W = df2.set_index('date').resample('16W').pad()

# Save to csv format
all_BNB_data_16W.to_csv('all_bnb_16W_ftx.csv')

df1.to_csv('bnb_ftx.csv')

"""## Get the data for BCH"""

base_currency = 'BCH'
quote_currency = 'USD'

# Specify the base and quote currencies to get single market data
request_url = f'{endpoint_url}/{base_currency}/{quote_currency}'

df3 = pd.DataFrame(requests.get(request_url).json())
df3['result']

# 1 day = 60 * 60 * 24 seconds
daily=str(60*60*24)

# Start date = 2022-04-01
start = datetime(2020, 5, 24).timestamp()

# Get the historical market data as JSON
historical = requests.get(
    f'{request_url}/candles?resolution={daily}&start_time={start}'
).json()

# Convert JSON to Pandas DataFrame
df3 = pd.DataFrame(historical['result'])

# Convert time to date
df3['date'] = pd.to_datetime(
    df3['time']/1000, unit='s', origin='unix'
) 

# Remove unnecessary columns
df3.drop(['startTime', 'time'], axis=1, inplace=True)
df3

## Collecting hourly and weekly data
all_bch_data_1H = df3.set_index('date').resample('1H').pad()
all_bch_data_2H = df3.set_index('date').resample('2H').pad()
all_bch_data_4H = df3.set_index('date').resample('4H').pad()
all_bch_data_8H = df3.set_index('date').resample('8H').pad()
all_bch_data_24H = df3.set_index('date').resample('24H').pad()
all_bch_data_48H = df3.set_index('date').resample('48H').pad()
all_bch_data_72H = df3.set_index('date').resample('72H').pad()

all_BCH_data_1W = df3.set_index('date').resample('1W').pad()
all_BCH_data_2W = df3.set_index('date').resample('2W').pad()
all_BCH_data_4W = df3.set_index('date').resample('4W').pad()
all_BCH_data_8W = df3.set_index('date').resample('8W').pad()
all_BCH_data_16W = df3.set_index('date').resample('16W').pad()

all_BCH_data_16W.to_csv('all_bch_data_16W.csv')

df3.to_csv('bch_ftx.csv')

"""## Get the Data for AVAX"""

base_currency = 'AVAX'
quote_currency = 'USD'

# Specify the base and quote currencies to get single market data
request_url = f'{endpoint_url}/{base_currency}/{quote_currency}'

df4 = pd.DataFrame(requests.get(request_url).json())
d4['result']

# 1 day = 60 * 60 * 24 seconds
daily=str(60*60*24)

# Start date = 2022-04-01
start = datetime(2020, 5, 24).timestamp()

# Get the historical market data as JSON
historical = requests.get(
    f'{request_url}/candles?resolution={daily}&start_time={start}'
).json()

# Convert JSON to Pandas DataFrame
df4 = pd.DataFrame(historical['result'])

# Convert time to date
df4['date'] = pd.to_datetime(
    df4['time']/1000, unit='s', origin='unix'
) 

# Remove unnecessary columns
df4.drop(['startTime', 'time'], axis=1, inplace=True)
df4
df4

## Collecting hourly and weekly data
all_AVAX_data_1H = df4.set_index('date').resample('1H').pad()
all_AVAX_data_2H = df4.set_index('date').resample('2H').pad()
all_AVAX_data_4H = df4.set_index('date').resample('4H').pad()
all_AVAX_data_8H = df4.set_index('date').resample('8H').pad()
all_AVAX_data_24H = df4.set_index('date').resample('24H').pad()
all_AVAX_data_48H = df4.set_index('date').resample('48H').pad()
all_AVAX_data_72H = df4.set_index('date').resample('72H').pad()

all_AVAX_data_1W = df4.set_index('date').resample('1W').pad()
all_AVAX_data_2W = df4.set_index('date').resample('2W').pad()
all_AVAX_data_4W = df4.set_index('date').resample('4W').pad()
all_AVAX_data_8W = df4.set_index('date').resample('8W').pad()
all_AVAX_data_16W = df4.set_index('date').resample('16W').pad()

all_AVAX_data_16W.to_csv('all_AVAX_data_16W')

df1.to_csv('avax_ftx.csv')

"""## Get the Data for SOL"""

base_currency = 'SOL'
quote_currency = 'USD'

# Specify the base and quote currencies to get single market data
request_url = f'{endpoint_url}/{base_currency}/{quote_currency}'

df5 = pd.DataFrame(requests.get(request_url).json())
df5['result']

# 1 day = 60 * 60 * 24 seconds
daily=str(60*60*24)

# Start date = 2022-04-01
start = datetime(2020, 5, 24).timestamp()

# Get the historical market data as JSON
historical = requests.get(
    f'{request_url}/candles?resolution={daily}&start_time={start}'
).json()

# Convert JSON to Pandas DataFrame
df5 = pd.DataFrame(historical['result'])

# Convert time to date
df5['date'] = pd.to_datetime(
    df5['time']/1000, unit='s', origin='unix'
) 

# Remove unnecessary columns
df5.drop(['startTime', 'time'], axis=1, inplace=True)
df5

## Collecting hourly and weekly data
all_SOL_data_1H = df5.set_index('date').resample('1H').pad()
all_SOL_data_2H = df5.set_index('date').resample('2H').pad()
all_SOL_data_4H = df5.set_index('date').resample('4H').pad()
all_SOL_data_8H = df5.set_index('date').resample('8H').pad()
all_SOL_data_24H = df5.set_index('date').resample('24H').pad()
all_SOL_data_48H = df5.set_index('date').resample('48H').pad()
all_SOL_data_72H = df5.set_index('date').resample('72H').pad()

all_SOL_data_1W = df5.set_index('date').resample('1W').pad()
all_SOL_data_2W = df5.set_index('date').resample('2W').pad()
all_SOL_data_4W = df5.set_index('date').resample('4W').pad()
all_SOL_data_8W = df5.set_index('date').resample('8W').pad()
all_SOL_data_16W = df5.set_index('date').resample('16W').pad()

all_SOL_data_16W.to_csv('all_SOL_data_16W')

df1.to_csv('sol_ftx.csv')


"""Get Data for DOT"""

base_currency = 'DOT'
quote_currency = 'USD'

# Specify the base and quote currencies to get single market data
request_url = f'{endpoint_url}/{base_currency}/{quote_currency}'

df6 = pd.DataFrame(requests.get(request_url).json())
df6['result']

"""Data from here started coming from 2021"""

# 1 day = 60 * 60 * 24 seconds
daily=str(60*60*24)

# Start date = 2022-04-01
start = datetime(2020, 5, 24).timestamp()

# Get the historical market data as JSON
historical = requests.get(
    f'{request_url}/candles?resolution={daily}&start_time={start}'
).json()

# Convert JSON to Pandas DataFrame|
df6 = pd.DataFrame(historical['result'])

# Convert time to date
df6['date'] = pd.to_datetime(
    df6['time']/1000, unit='s', origin='unix'
) 

# Remove unnecessary columns
df1.drop(['startTime', 'time'], axis=1, inplace=True)
df1

## Collecting hourly and weekly data
all_DOT_data_1H = df6.set_index('date').resample('1H').pad()
all_DOT_data_2H = df6.set_index('date').resample('2H').pad()
all_DOT_data_4H = df6.set_index('date').resample('4H').pad()
all_DOT_data_8H = df6.set_index('date').resample('8H').pad()
all_DOT_data_24H = df6.set_index('date').resample('24H').pad()
all_DOT_data_48H = df6.set_index('date').resample('48H').pad()
all_DOT_data_72H = df6.set_index('date').resample('72H').pad()

all_DOT_data_1W = df6.set_index('date').resample('1W').pad()
all_DOT_data_2W = df6.set_index('date').resample('2W').pad()
all_DOT_data_4W = df6.set_index('date').resample('4W').pad()
all_DOT_data_8W = df6.set_index('date').resample('8W').pad()
all_DOT_data_16W = df6.set_index('date').resample('16W').pad()

all_DOT_data_16W.to_csv('all_DOT_data_16W')

df1.to_csv('dot_ftx.csv')

"""Data for LTC"""

base_currency = 'LTC'
quote_currency = 'USD'

# Specify the base and quote currencies to get single market data
request_url = f'{endpoint_url}/{base_currency}/{quote_currency}'

df7 = pd.DataFrame(requests.get(request_url).json())
df7['result']

# 1 day = 60 * 60 * 24 seconds
daily=str(60*60*24)

# Start date = 2022-04-01
start = datetime(2020, 1, 1).timestamp()

# Get the historical market data as JSON
historical = requests.get(
    f'{request_url}/candles?resolution={daily}&start_time={start}'
).json()

# Convert JSON to Pandas DataFrame
df7 = pd.DataFrame(historical['result'])

# Convert time to date
df7['date'] = pd.to_datetime(
    df7['time']/1000, unit='s', origin='unix'
) 

# Remove unnecessary columns
df1.drop(['startTime', 'time'], axis=1, inplace=True)
df1
df1

## Collecting hourly and weekly data
all_ltc_data_1H = df7.set_index('date').resample('1H').pad()
all_ltc_data_2H = df7.set_index('date').resample('2H').pad()
all_ltc_data_4H = df7.set_index('date').resample('4H').pad()
all_ltc_data_8H = df7.set_index('date').resample('8H').pad()
all_ltc_data_24H = df7.set_index('date').resample('24H').pad()
all_ltc_data_48H = df7.set_index('date').resample('48H').pad()
all_ltc_data_72H = df7.set_index('date').resample('72H').pad()

all_ltc_data_72H.to_csv('all_ltc_data_72H.csv')

df1.to_csv('ltc_ftx.csv')

